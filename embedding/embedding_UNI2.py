#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LNMP_RAG: Tile-level embedding with UNI2-h (timm)
- ë¼ë²¨ì€ test_report.jsonì˜ GTë§Œ ì‚¬ìš©: "metastasis" | "nonmetastasis"
- IDS_TXTì— ì íŒ ìŠ¬ë¼ì´ë“œ ë””ë ‰í† ë¦¬ë§Œ ì„ë² ë”©
"""

import os
import json
from pathlib import Path
from typing import List, Dict
from PIL import Image
import numpy as np
from tqdm import tqdm

import torch
import timm
from chromadb import PersistentClient
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

# ======================
# âœ… Config
# ======================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ìŠ¬ë¼ì´ë“œ ë””ë ‰í† ë¦¬ ë£¨íŠ¸ (V1.0.0 ë°”ë¡œ ì•„ë˜ì— ìŠ¬ë¼ì´ë“œ í´ë”ë“¤ì´ ìˆì–´ì•¼ í•¨)
ROOT_DIR = Path("/home/mts/ssd_16tb/member/jks/lnmp_breast_data/V1.0.0")

# ì„ë² ë”©í•  ìŠ¬ë¼ì´ë“œ ID ëª©ë¡ (í•œ ì¤„ì— í•˜ë‚˜ì˜ ë””ë ‰í† ë¦¬ëª…) - ì˜ˆ: train_ids.txt í˜¹ì€ test_ids.txt
IDS_TXT = Path("/home/mts/ssd_16tb/member/jks/lnmp_breast_data/train_ids.txt")

# âœ… test_report (GT) ê²½ë¡œ: JSONë§Œ ì‚¬ìš©
# ì˜ˆ: {"BC_01_0001": "metastasis", "BC_01_0002": "nonmetastasis", ...}
TEST_REPORT_JSON = Path("/home/mts/ssd_16tb/member/jks/lnmp_RAG/embedding/test_report.json")

# ChromaDB (persistent)
CHROMA_PATH = Path("/home/mts/ssd_16tb/member/jks/lnmp_breast_data/vectordb/lnmp_RAG_embedding_db_v0.1.0")
COLLECTION_NAME = "lnmp_tile_embeddings_UNI2"

# ì´ë¯¸ì§€ í™•ì¥ì í—ˆìš©
IMG_EXTS = (".jpg", ".jpeg", ".png")


# ì´ë¯¸ì§€ í™•ì¥ì í—ˆìš© (ì´ë¯¸ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
IMG_EXTS = (".jpg", ".jpeg", ".png")

def list_tiles_recursive(root: Path) -> list[Path]:
    """root ì´í•˜ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ png/jpg íƒ€ì¼ì„ ì¬ê·€ì ìœ¼ë¡œ ìˆ˜ì§‘"""
    exts = {e.lower() for e in IMG_EXTS}
    return [p for p in root.rglob("*") if p.is_file() and p.suffix.lower() in exts]

def resolve_slide_root(slide_id: str) -> Path:
    """
    ìŠ¬ë¼ì´ë“œ ë£¨íŠ¸ ê²°ì •:
    1) ê¸°ë³¸: ROOT_DIR/slide_id
    2) ê°™ì€ ì´ë¦„ í•˜ìœ„ í´ë”ê°€ ìˆìœ¼ë©´: ROOT_DIR/slide_id/slide_id (ì˜ˆ: .../BC_01_0527/BC_01_0527)
    """
    base = ROOT_DIR / slide_id
    nested = base / slide_id
    return nested if nested.is_dir() else base


# ChromaDB add ë°°ì¹˜ í¬ê¸° (íƒ€ì¼ ìˆ˜ ë§ì„ ë•Œ ë©”ëª¨ë¦¬ ì•ˆì •í™”)
ADD_BATCH = 5000

# ======================
# âœ… Model (UNI2-h) & Transform
# ======================
timm_kwargs = {
    "img_size": 224,
    "patch_size": 14,
    "depth": 24,
    "num_heads": 24,
    "init_values": 1e-5,
    "embed_dim": 1536,
    "mlp_ratio": 2.66667 * 2,
    "num_classes": 0,
    "no_embed_class": True,
    "mlp_layer": timm.layers.SwiGLUPacked,
    "act_layer": torch.nn.SiLU,
    "reg_tokens": 8,
    "dynamic_img_size": True,
}
model = timm.create_model(
    "hf-hub:MahmoodLab/UNI2-h",
    pretrained=True,
    **timm_kwargs,
).to(DEVICE)
model.eval()

# ê¶Œì¥ ì „ì²˜ë¦¬
transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=model))

# ======================
# âœ… ChromaDB
# ======================
chroma_client = PersistentClient(path=str(CHROMA_PATH))
collection = chroma_client.get_or_create_collection(name=COLLECTION_NAME)

# ======================
# âœ… Utils
# ======================




def load_id_list(txt_path: Path) -> List[str]:
    with open(txt_path, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

def _norm_label(s: str) -> str:
    s = str(s).strip().lower()
    if s in {"1", "metastasis", "meta", "mets", "positive", "pos"}:
        return "metastasis"
    if s in {"0", "nonmetastasis", "non-metastasis", "non_meta", "nonmeta",
             "negative", "neg", "normal"}:
        return "nonmetastasis"
    return s  # ì˜ˆìƒ ë°– ê°’ì€ ê·¸ëŒ€ë¡œ ë°˜í™˜(ì•„ë˜ì—ì„œ ë°©ì–´)

def load_label_map_json(json_path: Path) -> Dict[str, str]:
    if not json_path.exists():
        raise FileNotFoundError(f"TEST_REPORT_JSON ë¯¸ì¡´ì¬: {json_path}")

    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    label_map: Dict[str, str] = {}

    # ìŠ¤í‚¤ë§ˆ A) { "BC_01_0001": "metastasis", ... }
    if isinstance(data, dict) and all(isinstance(v, (str, int)) for v in data.values()):
        label_map = {k: _norm_label(v) for k, v in data.items()}

    # ìŠ¤í‚¤ë§ˆ B) [ {"id":"...","label":"..."}, {"id":"...","report":"..."} ... ]
    elif isinstance(data, list) and all(isinstance(x, dict) for x in data):
        for row in data:
            sid = (row.get("id") or row.get("slide_id") or "").strip()
            lbl = row.get("label")
            if lbl is None:
                lbl = row.get("report")  # â† ì‚¬ìš©ìê°€ ì¤€ êµ¬ì¡° ì§€ì›
            if not sid or lbl is None:
                continue
            label_map[sid] = _norm_label(lbl)

    # ìŠ¤í‚¤ë§ˆ C) {"metastasis":{"train":[paths],...}, "non-metastasis":{...}}
    elif isinstance(data, dict) and any(k in data for k in ["metastasis", "non-metastasis", "nonmetastasis"]):
        def collect_ids(split_dict: dict) -> list[str]:
            ids = []
            for split_name in ("train", "valid", "test"):
                paths = split_dict.get(split_name, [])
                for p in paths:
                    sid = Path(p).name.strip()
                    if sid:
                        ids.append(sid)
            return ids

        if "metastasis" in data and isinstance(data["metastasis"], dict):
            for sid in collect_ids(data["metastasis"]):
                label_map[sid] = "metastasis"

        nonmeta_key = None
        for cand in ["non-metastasis", "nonmetastasis"]:
            if cand in data and isinstance(data[cand], dict):
                nonmeta_key = cand
                break
        if nonmeta_key:
            for sid in collect_ids(data[nonmeta_key]):
                label_map[sid] = "nonmetastasis"

    else:
        raise ValueError(f"test_report.json í˜•ì‹ ì˜¤ë¥˜(ì§€ì› ìŠ¤í‚¤ë§ˆ A/B/C): {json_path}")

    # ì•Œ ìˆ˜ ì—†ëŠ” ë¼ë²¨ ë°©ì–´
    bad = {k: v for k, v in label_map.items() if v not in {"metastasis", "nonmetastasis"}}
    if bad:
        print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë¼ë²¨ {len(bad)}ê±´: ì˜ˆì‹œ {list(bad.items())[:5]}")

    print(f"âœ… ë¼ë²¨ ë¡œë“œ ì™„ë£Œ: {len(label_map)} slides from {json_path}")
    if label_map:
        print("   ì˜ˆì‹œ:", list(label_map.items())[:5])
    return label_map

@torch.inference_mode()
def get_embedding(img_path: Path) -> np.ndarray:
    # PIL ImageëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¡œ ì•ˆì „í•˜ê²Œ ì—´ê¸°
    with Image.open(img_path) as im:
        image = im.convert("RGB")
    tensor = transform(image).unsqueeze(0).to(DEVICE)
    use_amp = (DEVICE.type == "cuda")
    if use_amp:
        with torch.autocast("cuda", dtype=torch.float16):
            feat = model(tensor)  # [1, 1536]
    else:
        feat = model(tensor)
    feat = torch.nn.functional.normalize(feat, dim=-1)  # L2 ì •ê·œí™”
    return feat.squeeze(0).detach().cpu().numpy()

def embed_and_store(slide_root: Path, slide_id: str, label: str):
    files = list_tiles_recursive(slide_root)   # â† ì¬ê·€ì ìœ¼ë¡œ ì „ë¶€ ì°¾ê¸°
    if not files:
        print(f"âš ï¸ íƒ€ì¼ ì—†ìŒ: {slide_root}")
        return

    # ê¸°ì¡´ ë™ì¼ slide_id ë°ì´í„° ì‚­ì œ í›„ ì¬ì‚½ì…
    collection.delete(where={"slide_id": slide_id})

    embeddings, ids, metadatas = [], [], []
    for img_path in tqdm(files, desc=f"Embedding {slide_id}", leave=False):
        emb = get_embedding(img_path)
        embeddings.append(emb.tolist())

        # ê³ ìœ  IDëŠ” íŒŒì¼ëª…ë§Œ ì¨ë„ ë˜ì§€ë§Œ, ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ìƒëŒ€ê²½ë¡œ ì‚¬ìš© ê¶Œì¥
        rel = img_path.relative_to(slide_root)
        ids.append(f"{slide_id}_{rel.as_posix()}")

        metadatas.append({
            "slide_id": slide_id,
            "tile_name": rel.name,
            "tile_path": str(img_path),
            "label": label,
        })

        if len(ids) >= ADD_BATCH:
            collection.add(embeddings=embeddings, ids=ids, metadatas=metadatas)
            embeddings, ids, metadatas = [], [], []

    if ids:
        collection.add(embeddings=embeddings, ids=ids, metadatas=metadatas)

    print(f"ğŸ“Š {slide_id} íƒ€ì¼ ìˆ˜: {len(files)} @ {slide_root}")
    print(json.dumps(metadatas[:2], ensure_ascii=False, indent=2) if metadatas else "  (empty)")

# ======================
# âœ… Main
# ======================
if __name__ == "__main__":
    # 1) ì„ë² ë”© ëŒ€ìƒ ìŠ¬ë¼ì´ë“œ
    ids = load_id_list(IDS_TXT)

    # 2) GT ë¼ë²¨ ë¡œë“œ (test_report.json)
    label_map = load_label_map_json(TEST_REPORT_JSON)

    # 3) ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í´ë”ë§Œ í•„í„°
    exist_ids = [sid for sid in ids if (ROOT_DIR / sid).is_dir()]
    miss = set(ids) - set(exist_ids)
    if miss:
        print(f"âš ï¸ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í´ë” {len(miss)}ê°œ ìŠ¤í‚µ: {sorted(list(miss))[:5]} ...")

    # 4) ë¼ë²¨ ë§¤í•‘ ëˆ„ë½ í™•ì¸
    no_label = [sid for sid in exist_ids if sid not in label_map]
    if no_label:
        print(f"âš ï¸ GT ë¼ë²¨ ëˆ„ë½ {len(no_label)}ê°œ: ì˜ˆì‹œ {no_label[:10]}")
        print("   â†’ ëˆ„ë½ ìŠ¬ë¼ì´ë“œëŠ” ê¸°ë³¸ê°’ 'nonmetastasis'ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # 5) ì§„í–‰ ì •ë³´
    print(f"ì„ë² ë”© ëŒ€ìƒ ìŠ¬ë¼ì´ë“œ: {len(exist_ids)} (from {IDS_TXT.name})")
    print(f"ë¼ë²¨ ë³´ìœ  ìŠ¬ë¼ì´ë“œ:   {len(label_map)} (from {TEST_REPORT_JSON.name})")

    # 6) ìŠ¬ë¼ì´ë“œë³„ ì„ë² ë”©
    for slide_id in exist_ids:
        label = label_map.get(slide_id, "nonmetastasis")
        if label not in {"metastasis", "nonmetastasis"}:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë¼ë²¨ ê°’ '{label}' â†’ 'nonmetastasis'ë¡œ ëŒ€ì²´ ({slide_id})")
            label = "nonmetastasis"

        slide_dir = ROOT_DIR / slide_id
        try:
            embed_and_store(slide_dir, slide_id, label)
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {slide_id} ({label})")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {slide_id} â†’ {e}")
