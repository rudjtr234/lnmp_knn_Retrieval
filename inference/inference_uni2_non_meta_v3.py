# -*- coding: utf-8 -*-

"""
KNN ê¸°ë°˜ META/NON-META íƒ€ì¼ íŒì • (HNSW Index ë¶ˆëŸ¬ì˜¤ê¸° ë²„ì „, v3)
- Ï„ (tau_low, tau_high)ëŠ” cal_tau.pyì—ì„œ ë¯¸ë¦¬ ê³„ì‚°/ì €ì¥ë¨
- HNSW Indexë„ ë¯¸ë¦¬ ìƒì„±ëœ index.faiss ë¶ˆëŸ¬ì™€ì„œ ì‚¬ìš©
- ëª¨ë“  rankì—ì„œ ì„ë² ë”© ê³„ì‚° + ìŠ¬ë¼ì´ë“œë³„ ì§„í–‰ìƒí™© ì¶œë ¥
- Rank 0ì—ì„œë§Œ ìµœì¢… ê²°ê³¼ í•©ì³ì„œ JSON ì €ì¥
- ì‹¤í–‰ ëª…ë ¹ì–´ : CUDA_VISIBLE_DEVICES=0,1,2 torchrun   --nproc_per_node=3   --master_addr=192.168.20.144   --master_port=12355   inference_uni2_non_meta_v3.py

"""

import os, json
from pathlib import Path
from typing import List
import numpy as np
import torch
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from PIL import Image, ImageFile
import timm
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform
from timm.layers import SwiGLUPacked
import faiss

from visualize_result import make_overlay_slide

ImageFile.LOAD_TRUNCATED_IMAGES = True

# =========================
# ì„¤ì •
# =========================
BASE_ROOT   = Path("/home/mts/ssd_16tb/member/jks/lnmp_breast_data")
BASE_ROOT_2 = Path("/home/mts/ssd_16tb/member/jks/lnmp_breast_data/vectordb/faiss")
BASE_ROOT_3 = Path("/home/mts/ssd_16tb/member/jks/lnmp_breast_data/tau")
BASE_ROOT_4 = Path("/home/mts/ssd_16tb/member/jks/lnmp_knn_Retrieval/inference")
BASE_ROOT_5 = Path("/home/mts/ssd_16tb/member/jks/lnmp_knn_Retrieval/inference/result")
BASE_ROOT_6 = Path("/home/mts/ssd_16tb/member/jks/lnmp_knn_Retrieval/eval")


VERSION_DIR = BASE_ROOT / "V1.0.1"
ROOT_DIR    = VERSION_DIR
TEST_IDS_TXT = BASE_ROOT_4 / "label/answer_label.txt"

K_NEIGHBORS     = 5
SLIDE_RATIO_THR = 0.005
MIN_META_COUNT  = 10
VALID_EXTS      = {".jpg", ".jpeg", ".png", ".bmp"}

# Ï„ / Index ê²½ë¡œ
TAU_FILE   = BASE_ROOT_3 / "tau_params_v0.1.3.json"
INDEX_FILE = BASE_ROOT_2 / "hnsw_index_v0.1.0.faiss"

# =========================
# DDP Setup
# =========================
from datetime import timedelta

def setup(rank, world_size):
    # í™˜ê²½ ë³€ìˆ˜ ì„¸íŒ…
    os.environ["NCCL_ASYNC_ERROR_HANDLING"] = "1"
    os.environ["NCCL_BLOCKING_WAIT"] = "1"
    os.environ["NCCL_DEBUG"] = "INFO"
    os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

    dist.init_process_group(
        backend="nccl",
        init_method="env://",
        world_size=world_size,
        rank=rank,
        timeout=timedelta(hours=24)  # í•„ìš” ì‹œ ì¤„ì—¬ë„ ë¨
    )
    torch.cuda.set_device(rank)
    print(f"[Rank {rank}] Process group initialized (world_size={world_size})", flush=True)

def cleanup():
    try:
        dist.destroy_process_group()
    except Exception as e:
        print(f"[Rank Cleanup] NCCL ì¢…ë£Œ ì˜¤ë¥˜ ë¬´ì‹œ: {e}", flush=True)

# =========================
# ìœ í‹¸ í•¨ìˆ˜
# =========================
def l2_normalize(x: torch.Tensor, dim: int = -1, eps: float = 1e-12) -> torch.Tensor:
    return x / (x.norm(dim=dim, keepdim=True) + eps)

def read_test_ids(path: Path) -> List[str]:
    with open(path, "r") as f:
        return [line.strip() for line in f if line.strip()]

def list_tiles(slide_dir: Path) -> List[Path]:
    return sorted([p for p in slide_dir.iterdir() if p.is_file() and p.suffix.lower() in VALID_EXTS])

@torch.no_grad()
def embed_images(img_list, model, transform, device, batch_size=256):
    embs = []
    for i in range(0, len(img_list), batch_size):
        batch = img_list[i:i+batch_size]
        x = torch.stack([transform(img) for img in batch]).to(device, non_blocking=True)
        feats = model.module.forward_features(x) if isinstance(model, DDP) else model.forward_features(x)
        if feats.ndim == 3:
            feats = feats[:, 0, :]
        elif feats.ndim == 4:
            feats = feats.mean(dim=(2, 3))
        feats = l2_normalize(feats, dim=-1)
        embs.append(feats.detach().cpu())
    return torch.cat(embs, dim=0).numpy().astype(np.float32)

def slide_decision(meta_count: int, total_tiles: int, ratio_thr: float, min_meta: int) -> str:
    ratio = (meta_count / max(total_tiles, 1))
    return "META" if (meta_count >= min_meta and ratio >= ratio_thr) else "NON_META"


# =========================
# Main Worker
# =========================

def main_worker(rank, world_size):
    setup(rank, world_size)

    # === ëª¨ë¸ ë¡œë“œ ===
    timm_kwargs = {
        "img_size": 224, "patch_size": 14, "depth": 24, "num_heads": 24,
        "init_values": 1e-5, "embed_dim": 1536, "mlp_ratio": 2.66667*2,
        "num_classes": 0, "no_embed_class": True,
        "mlp_layer": SwiGLUPacked, "act_layer": torch.nn.SiLU,
        "reg_tokens": 8, "dynamic_img_size": True,
    }
    model = timm.create_model("hf-hub:MahmoodLab/UNI2-h", pretrained=True, **timm_kwargs)
    model = model.to(rank)
    model = DDP(model, device_ids=[rank], output_device=rank)
    model.eval()
    data_cfg = resolve_data_config({}, model=model.module)
    transform = create_transform(**data_cfg)

    # === Rank0: Ï„ ê°’ + Index ë¶ˆëŸ¬ì˜¤ê¸° ===
    if rank == 0:
        with open(TAU_FILE, "r") as f:
            tau = json.load(f)
        tau_low, tau_high = tau["tau_low"], tau["tau_high"]
        hnsw_index = faiss.read_index(str(INDEX_FILE))
        print(f"[Rank0] ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: tau_low={tau_low:.6f}, tau_high={tau_high:.6f}, index={INDEX_FILE}")
    else:
        tau_low, tau_high, hnsw_index = None, None, None

    # === Ï„ ê°’ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ===
    tau_low = torch.tensor([tau_low if tau_low is not None else 0.0], device=rank)
    tau_high = torch.tensor([tau_high if tau_high is not None else 0.0], device=rank)
    dist.broadcast(tau_low, src=0)
    dist.broadcast(tau_high, src=0)
    tau_low, tau_high = tau_low.item(), tau_high.item()

    # === í…ŒìŠ¤íŠ¸ ìŠ¬ë¼ì´ë“œ ë¶„ë°° ===
    test_ids = read_test_ids(TEST_IDS_TXT)
    my_ids = test_ids[rank::world_size]
    per_slide = []
    for idx, sid in enumerate(my_ids, 1):
        slide_dir = ROOT_DIR / sid / sid
        if not slide_dir.exists():
            alt_dir = ROOT_DIR / sid
            if alt_dir.exists():
                slide_dir = alt_dir
        tiles = list_tiles(slide_dir)
        if len(tiles) == 0:
            per_slide.append({"id": f"{sid}.svs", "embs": None, "tiles": []})
            continue
        imgs = [Image.open(tp).convert("RGB") for tp in tiles if tp.exists()]
        embs = embed_images(imgs, model, transform, rank, batch_size=256)
        print(f"[Rank {rank}] {idx}/{len(my_ids)} ìŠ¬ë¼ì´ë“œ ì™„ë£Œ: {sid} (tiles={len(embs)})", flush=True)
        per_slide.append({"id": f"{sid}.svs", "embs": embs, "tiles": tiles})

    # === ê²°ê³¼ ìˆ˜ì§‘ ===
    gather_list = [None for _ in range(world_size)]
    dist.all_gather_object(gather_list, per_slide)

    if rank == 0:
        merged = []
        for r in gather_list:
            for entry in r:
                sid = entry["id"]
                if entry["embs"] is None:
                    merged.append({"id": sid, "metastasis": 0})
                    continue
                embs = entry["embs"]
                tiles = entry["tiles"]

                # === ì €ì¥ëœ HNSW indexì—ì„œ Top-K ê²€ìƒ‰ ===
                dists, _ = hnsw_index.search(embs.astype(np.float32), K_NEIGHBORS)
                scores = dists

                # === META/NON-META íŒì • ===
                is_meta = []
                for row in scores:
                    if np.all(row >= tau_high):
                        # í™•ì‹¤íˆ META
                        is_meta.append(True)
                    elif np.all(row <= tau_low):
                        # í™•ì‹¤íˆ NON-META
                        is_meta.append(False)
                    else:
                        # í ½í´¥ ì• ë§¤ êµ¬ê°„ â†’ 5ê°œ ì´ì›ƒ ë§Œì¥ì¼ì¹˜ ê²€ì‚¬
                        votes = [(d >= tau_high) for d in row]
                        if all(votes):
                            is_meta.append(True)   # 5ê°œ ë‹¤ META
                        else:
                            is_meta.append(False)  # í•˜ë‚˜ë¼ë„ ì•„ë‹ˆë©´ NON-META

                is_meta = np.array(is_meta)

                meta_cnt = int(np.sum(is_meta))
                all_cnt = len(is_meta)
                slide_pred = slide_decision(meta_cnt, all_cnt, SLIDE_RATIO_THR, MIN_META_COUNT)
                merged.append({"id": sid, "metastasis": 1 if slide_pred == "META" else 0})
                print(f"[Rank0] ìµœì¢… - {sid}: tiles={all_cnt}, META={meta_cnt} "
                      f"({(meta_cnt/all_cnt*100):.3f}%), -> {slide_pred}", flush=True)
                make_overlay_slide(
                    slide_id=sid.replace(".svs", ""),
                    tiles=tiles,
                    is_meta=is_meta,
                    tile_size=512,
                    out_dir=BASE_ROOT_2 / "wsi_image"
                )

        out_json = BASE_ROOT_6 / f"lnmp_predictions_v0.2.3.json"
        with open(out_json, "w") as f:
            json.dump(merged, f, indent=2, ensure_ascii=False)
        print(f"\nâœ… ì „ì²´ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {out_json}")

    cleanup()


# =========================
# ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
# =========================
def main():
    world_size = int(os.environ["WORLD_SIZE"])
    rank = int(os.environ["RANK"])
    main_worker(rank, world_size)

if __name__ == "__main__":
    main()
