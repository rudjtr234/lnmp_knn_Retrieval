#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
KNN ìµœê·¼ì ‘ ê±°ë¦¬ ê¸°ë°˜ META/NON-META íƒ€ì¼ íŒì • + ìŠ¬ë¼ì´ë“œ ì§‘ê³„(JSON ì¶œë ¥)
- ë°°ê²½(non-meta) ì„ë² ë”©ìœ¼ë¡œ ì„ê³„ì¹˜ tauë¥¼ ì§€ì •(ë¶„ìœ„ìˆ˜ q%)
- ê° íƒ€ì¼ì˜ 'ë°°ê²½ê¹Œì§€ì˜ ìµœê·¼ì ‘ kNN ê±°ë¦¬'ê°€ tauë³´ë‹¤ í¬ë©´ META, ì‘ìœ¼ë©´ NON-META
- ìŠ¬ë¼ì´ë“œ ì§‘ê³„: META íƒ€ì¼ ë¹„ìœ¨ì´ RATIO ì´ìƒì´ê³ , META íƒ€ì¼ ìˆ˜ê°€ MIN_META_COUNT ì´ìƒì´ë©´ ìŠ¬ë¼ì´ë“œ META
- ìµœì¢… ì¶œë ¥: [{ "id": "<slide>.svs", "metastasis": 0/1 }, ...]
"""

import os, re, json
from pathlib import Path
from typing import List, Tuple
from visualize_result import make_overlay_slide
import numpy as np
import torch
from PIL import Image, ImageFile
from chromadb import PersistentClient
from tqdm import tqdm

import timm
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform
from timm.layers import SwiGLUPacked

import faiss   # GPU KNN ë¼ì´ë¸ŒëŸ¬ë¦¬

ImageFile.LOAD_TRUNCATED_IMAGES = True

# =========================
# ì„¤ì •
# =========================
BASE_ROOT = Path("/home/mts/ssd_16tb/member/jks/lnmp_breast_data")
BASE_ROOT_2 = Path("/home/mts/ssd_16tb/member/jks/lnmp_RAG/inference/result")
BASE_ROOT_3 = Path("/home/mts/ssd_16tb/member/jks/lnmp_RAG/inference")
VERSION_DIR = BASE_ROOT / "V1.0.0"
ROOT_DIR = VERSION_DIR
TEST_IDS_TXT = BASE_ROOT_3 / "test_ids.txt"
DB_PATH  = BASE_ROOT / "vectordb/lnmp_RAG_embedding_db_v0.2.0"

COLLECTION_NAME_BG   = "lnmp_non_meta_tile_embeddings_UNI2"

K_NEIGHBORS     = 5
Q_PERCENT       = 99.99
MAX_BG          = None
SLIDE_RATIO_THR = 0.005
MIN_META_COUNT  = 10

VALID_EXTS = {".jpg", ".jpeg", ".png", ".bmp"}
SLIDE_RE = re.compile(r"(BC_\d+_\d+)")

# =========================
# ë””ë°”ì´ìŠ¤ & ëª¨ë¸
# =========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("âœ… Using device:", device)
if torch.cuda.is_available():
    print("   - GPU count:", torch.cuda.device_count())

timm_kwargs = {
    "img_size": 224, "patch_size": 14, "depth": 24, "num_heads": 24,
    "init_values": 1e-5, "embed_dim": 1536, "mlp_ratio": 2.66667*2,
    "num_classes": 0, "no_embed_class": True,
    "mlp_layer": SwiGLUPacked, "act_layer": torch.nn.SiLU,
    "reg_tokens": 8, "dynamic_img_size": True,
}

model = timm.create_model("hf-hub:MahmoodLab/UNI2-h", pretrained=True, **timm_kwargs)
if torch.cuda.device_count() > 1:
    print("âœ… Multi-GPU DataParallel enabled")
    model = torch.nn.DataParallel(model)

model = model.to(device)
model.eval()
data_cfg = resolve_data_config({}, model=model)
transform = create_transform(**data_cfg)

# =========================
# ìœ í‹¸
# =========================
def l2_normalize(x: torch.Tensor, dim: int = -1, eps: float = 1e-12) -> torch.Tensor:
    return x / (x.norm(dim=dim, keepdim=True) + eps)

def read_test_ids(path: Path) -> List[str]:
    with open(path, "r") as f:
        return [line.strip() for line in f if line.strip()]

def list_tiles(slide_dir: Path) -> List[Path]:
    return sorted([p for p in slide_dir.iterdir() if p.is_file() and p.suffix.lower() in VALID_EXTS])

@torch.no_grad()
def embed_images(img_list, batch_size=256):
    embs = []
    for i in range(0, len(img_list), batch_size):
        batch = img_list[i:i+batch_size]
        x = torch.stack([transform(img) for img in batch]).to(device)

        if isinstance(model, torch.nn.DataParallel):
            feats = model.module.forward_features(x)
        else:
            feats = model.forward_features(x)

        if feats.ndim == 3:
            feats = feats[:, 0, :]  # CLS í† í°
        elif feats.ndim == 4:
            feats = feats.mean(dim=(2, 3))  # GAP

        feats = l2_normalize(feats, dim=-1)
        embs.append(feats.detach().cpu())

    return torch.cat(embs, dim=0).numpy().astype(np.float32)

def build_bg_matrix_from_chroma(client, collection_name: str, max_bg: int = None):
    col = client.get_or_create_collection(collection_name)
    cnt = col.count()
    if cnt == 0:
        raise RuntimeError(f"[ë°°ê²½ ì„ë² ë”© ëˆ„ë½] ì»¬ë ‰ì…˜ '{collection_name}' ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    limit = cnt if max_bg is None else min(cnt, max_bg)
    got = col.get(include=["embeddings"], limit=limit)
    return np.array(got["embeddings"], dtype=np.float32)

def batched_search(index, embs: np.ndarray, k: int, batch_size: int = 64):
    all_dist, all_idx = [], []
    for i in range(0, len(embs), batch_size):
        batch = embs[i:i+batch_size]
        batch = batch.reshape(batch.shape[0], -1)

        if batch.shape[1] != index.d:
            raise ValueError(f"[Shape Mismatch] batch dim={batch.shape[1]}, index dim={index.d}")

        d, idx = index.search(batch.astype(np.float32), k)
        all_dist.append(d)
        all_idx.append(idx)

    return np.vstack(all_dist), np.vstack(all_idx)

def calibrate_tau_with_bg_faiss_gpu(
    X_bg: np.ndarray, k: int, q_percent: float, batch_size: int = 16, device: int = 0
):
    """Ï„ ê³„ì‚°ì€ GPU í•œ ì¥ì—ì„œë§Œ (ì•ˆì •ì )"""
    d = X_bg.shape[1]
    cpu_index = faiss.IndexFlatL2(d)
    res = faiss.StandardGpuResources()
    gpu_index = faiss.index_cpu_to_gpu(res, device, cpu_index)

    gpu_index.add(X_bg.astype(np.float32))

    distances, _ = batched_search(gpu_index, X_bg, k+1, batch_size=batch_size)
    scores_bg = distances[:, 1]
    tau = float(np.percentile(scores_bg, q_percent))
    return tau, scores_bg

def slide_decision(meta_count: int, total_tiles: int, ratio_thr: float, min_meta: int) -> str:
    ratio = (meta_count / max(total_tiles, 1))
    return "META" if (meta_count >= min_meta and ratio >= ratio_thr) else "NON_META"

# =========================
# ë©”ì¸
# =========================
def main():
    print("=== LNMP_RAG: META/NON-META ì¶”ë¡ (FAISS-KNN-Ï„, 5-NN ë§Œì¥ì¼ì¹˜, Single GPU) ===")

    # -------------------------
    # í…ŒìŠ¤íŠ¸ ìŠ¬ë¼ì´ë“œ ëª©ë¡
    # -------------------------
    test_ids = read_test_ids(TEST_IDS_TXT)
    print(f"- í…ŒìŠ¤íŠ¸ ìŠ¬ë¼ì´ë“œ ìˆ˜: {len(test_ids)}")

    # -------------------------
    # ë°°ê²½ ì„ë² ë”© ë¡œë“œ
    # -------------------------
    client = PersistentClient(path=str(DB_PATH))
    X_bg = build_bg_matrix_from_chroma(client, COLLECTION_NAME_BG, MAX_BG)
    print(f"- ë°°ê²½ ì„ë² ë”© ë¡œë“œ ì™„ë£Œ (shape={X_bg.shape})")

    # -------------------------
    # Ï„ ê³„ì‚° (GPU0 ë‹¨ì¼ ì¹´ë“œì—ì„œë§Œ)
    # -------------------------
    tau, bg_scores = calibrate_tau_with_bg_faiss_gpu(
        X_bg, k=1, q_percent=Q_PERCENT, batch_size=16, device=0
    )
    print(f"- tau (Q={Q_PERCENT}%): {tau:.6f}")

    # -------------------------
    # ì¶”ë¡ ìš© ì¸ë±ìŠ¤ (GPU0 ë‹¨ì¼ ì¹´ë“œ)
    # -------------------------
    d = X_bg.shape[1]
    cpu_index = faiss.IndexFlatL2(d)
    res = faiss.StandardGpuResources()
    index = faiss.index_cpu_to_gpu(res, 0, cpu_index)  # GPU0 í•œ ì¥ë§Œ ì‚¬ìš©
    index.add(X_bg.astype(np.float32))

    # -------------------------
    # ìŠ¬ë¼ì´ë“œë³„ ì¶”ë¡ 
    # -------------------------
    per_slide = []

    for sid in tqdm(test_ids, desc="Slides"):
        slide_dir = ROOT_DIR / sid / sid
        if not slide_dir.exists():
            alt_dir = ROOT_DIR / sid
            if alt_dir.exists():
                slide_dir = alt_dir

        tiles = list_tiles(slide_dir)
        if len(tiles) == 0:
            per_slide.append({"id": f"{sid}.svs", "metastasis": 0})
            continue

        # íƒ€ì¼ ë¡œë“œ
        imgs = []
        for tp in tiles:
            try:
                imgs.append(Image.open(tp).convert("RGB"))
            except:
                continue

        # === GPU ì„ë² ë”© ===
        embs = embed_images(imgs, batch_size=256)

        # === FAISS KNN ê²€ìƒ‰ ===
        distances, _ = batched_search(index, embs, K_NEIGHBORS, batch_size=16)
        scores = distances[:, 1:K_NEIGHBORS+1]

        # âœ… 5ê°œ ëª¨ë‘ tauë³´ë‹¤ ì»¤ì•¼ META
        is_meta = np.all(scores > tau, axis=1)

        # ìŠ¬ë¼ì´ë“œ ì§‘ê³„
        meta_cnt = int(np.sum(is_meta))
        all_cnt = len(is_meta)
        slide_pred = slide_decision(meta_cnt, all_cnt, SLIDE_RATIO_THR, MIN_META_COUNT)

        per_slide.append({
            "id": f"{sid}.svs",
            "metastasis": 1 if slide_pred == "META" else 0
        })

        print(f"  - {sid}: tiles={all_cnt}, META={meta_cnt} "
              f"({(meta_cnt/all_cnt*100):.3f}%), -> {slide_pred}")

        # ğŸ”¥ Overlay JPG ì €ì¥
        make_overlay_slide(
            slide_id=sid,
            tiles=tiles,
            is_meta=is_meta,
            tile_size=512,
            out_dir=BASE_ROOT_2 / "wsi_image"
        )

    # -------------------------
    # ê²°ê³¼ JSON ì €ì¥
    # -------------------------
    out_json = BASE_ROOT_2 / f"lnmp_predictions_v.0.1.0.json"
    with open(out_json, "w") as f:
        json.dump(per_slide, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {out_json}")


if __name__ == "__main__":
    main()
