#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
KNN ìµœê·¼ì ‘ ê±°ë¦¬ ê¸°ë°˜ META/NON-META íƒ€ì¼ íŒì • + ìŠ¬ë¼ì´ë“œ ì§‘ê³„(JSON ì¶œë ¥, Virchow2 ì „ìš©)
- ë°°ê²½(non-meta) ì„ë² ë”©ìœ¼ë¡œ ì„ê³„ì¹˜ tauë¥¼ ì§€ì •(ë¶„ìœ„ìˆ˜ q%)
- ê° íƒ€ì¼ì˜ 'ë°°ê²½ê¹Œì§€ì˜ ìµœê·¼ì ‘ kNN ê±°ë¦¬'ê°€ tauë³´ë‹¤ í¬ë©´ META, ì‘ìœ¼ë©´ NON-META
- ìŠ¬ë¼ì´ë“œ ì§‘ê³„: META íƒ€ì¼ ë¹„ìœ¨ì´ RATIO ì´ìƒì´ê³ , META íƒ€ì¼ ìˆ˜ê°€ MIN_META_COUNT ì´ìƒì´ë©´ ìŠ¬ë¼ì´ë“œ META
- ìµœì¢… ì¶œë ¥: [{ "id": "<slide>.svs", "metastasis": 0/1 }, ...]
"""

import os, re, json
from pathlib import Path
from typing import List
from visualize_result import make_overlay_slide
import numpy as np
import torch
from PIL import Image, ImageFile
from chromadb import PersistentClient
from tqdm import tqdm
from timm.layers import SwiGLUPacked
import timm
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

import faiss   # GPU KNN ë¼ì´ë¸ŒëŸ¬ë¦¬

ImageFile.LOAD_TRUNCATED_IMAGES = True

# =========================
# ì„¤ì •
# =========================
BASE_ROOT = Path("/home/mts/ssd_16tb/member/jks/lnmp_breast_data")
BASE_ROOT_2 = Path("/home/mts/ssd_16tb/member/jks/lnmp_knn_Retrieval/inference/result")
BASE_ROOT_3 = Path("/home/mts/ssd_16tb/member/jks/lnmp_knn_Retrieval/inference/")
VERSION_DIR = BASE_ROOT / "V1.0.1"
ROOT_DIR = VERSION_DIR
TEST_IDS_TXT = BASE_ROOT_3 / "label/answer_label.txt"
DB_PATH  = BASE_ROOT / "vectordb/lnmp_RAG_embedding_db_v0.3.0"

# ğŸ‘‰ Virchow2 ì „ìš© ë°°ê²½ DB
COLLECTION_NAME_BG   = "lnmp_non_meta_tile_embeddings_Virchow2"

K_NEIGHBORS     = 5
Q_PERCENT       = 99.99
MAX_BG          = None
SLIDE_RATIO_THR = 0.005
MIN_META_COUNT  = 10

VALID_EXTS = {".jpg", ".jpeg", ".png", ".bmp"}
SLIDE_RE = re.compile(r"(BC_\d+_\d+)")

# =========================
# ë””ë°”ì´ìŠ¤ & ëª¨ë¸ (Virchow2, Multi-GPU for embedding)
# =========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("âœ… Using device:", device)
if torch.cuda.is_available():
    print("   - GPU count:", torch.cuda.device_count())

# Virchow2 timm ëª¨ë¸ ë¡œë“œ (ê³µì‹ ê¶Œì¥ ë°©ì‹)
base_model = timm.create_model(
    "hf-hub:paige-ai/Virchow2",
    pretrained=True,
    num_classes=0,
    mlp_layer=SwiGLUPacked,       # ë°˜ë“œì‹œ ì§€ì •
    act_layer=torch.nn.SiLU,      # ë°˜ë“œì‹œ ì§€ì •
).to(device).eval()

# âœ… DataParallel ì ìš© (GPU 0,1,2 ì‚¬ìš©)
if torch.cuda.device_count() > 1:
    print("âœ… Multi-GPU DataParallel enabled (using GPU 0,1,2 for embedding)")
    model = torch.nn.DataParallel(base_model, device_ids=[0, 1, 2])
else:
    model = base_model

# Virchow2 ì „ì²˜ë¦¬ transform
data_cfg = resolve_data_config(model.module.pretrained_cfg if isinstance(model, torch.nn.DataParallel) else model.pretrained_cfg, model=model)
transform = create_transform(**data_cfg)


@torch.no_grad()
def embed_images(img_list, batch_size=256):
    """
    Virchow2 ê¸°ë°˜ íƒ€ì¼ ì„ë² ë”© ì¶”ì¶œ (Multi-GPU DataParallel ì§€ì›)
    ì¶œë ¥: numpy array (N, 2560)
         (CLS í† í° 1280 + íŒ¨ì¹˜ í‰ê·  1280 â†’ concat â†’ normalize)
    """
    embs = []
    for i in range(0, len(img_list), batch_size):
        batch = img_list[i:i+batch_size]
        if not batch:
            continue

        x = torch.stack([transform(img) for img in batch]).to(device, non_blocking=True)

        with torch.autocast("cuda", dtype=torch.float16):  # Mixed precision ê¶Œì¥
            out = model(x)  # (B, 261, 1280)  â†’ DataParallelì´ë©´ ìë™ìœ¼ë¡œ ë¶„ì‚° ì²˜ë¦¬

        cls_tok = out[:, 0]                # (B, 1280)
        patch_toks = out[:, 5:]            # (B, 256, 1280), ì• 4ê°œëŠ” register tokens ì œì™¸
        pooled_patch = patch_toks.mean(1)  # (B, 1280)

        z = torch.cat([cls_tok, pooled_patch], dim=-1)  # (B, 2560)
        z = torch.nn.functional.normalize(z, p=2, dim=-1)

        embs.append(z.cpu().numpy().astype("float32"))

    if not embs:
        return np.empty((0, 2560), dtype=np.float32)
    return np.concatenate(embs, axis=0)

# =========================
# ìœ í‹¸
# =========================
def read_test_ids(path: Path) -> List[str]:
    with open(path, "r") as f:
        return [line.strip() for line in f if line.strip()]

def list_tiles(slide_dir: Path) -> List[Path]:
    return sorted([p for p in slide_dir.iterdir() if p.is_file() and p.suffix.lower() in VALID_EXTS])

def build_bg_matrix_from_chroma(client, collection_name: str, max_bg: int = None):
    col = client.get_or_create_collection(collection_name)
    cnt = col.count()
    if cnt == 0:
        raise RuntimeError(f"[ë°°ê²½ ì„ë² ë”© ëˆ„ë½] ì»¬ë ‰ì…˜ '{collection_name}' ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    limit = cnt if max_bg is None else min(cnt, max_bg)
    got = col.get(include=["embeddings"], limit=limit)
    return np.array(got["embeddings"], dtype=np.float32)

def batched_search(index, embs: np.ndarray, k: int, batch_size: int = 64):
    all_dist, all_idx = [], []
    for i in range(0, len(embs), batch_size):
        batch = embs[i:i+batch_size]
        d, idx = index.search(batch.astype(np.float32), k)
        all_dist.append(d)
        all_idx.append(idx)
    return np.vstack(all_dist), np.vstack(all_idx)

def calibrate_tau_with_bg_faiss_gpu(
    X_bg: np.ndarray, k: int, q_percent: float, batch_size: int = 16, device: int = 0
):
    d = X_bg.shape[1]
    cpu_index = faiss.IndexFlatL2(d)
    res = faiss.StandardGpuResources()
    gpu_index = faiss.index_cpu_to_gpu(res, device, cpu_index)

    gpu_index.add(X_bg.astype(np.float32))

    distances, _ = batched_search(gpu_index, X_bg, k+1, batch_size=batch_size)
    scores_bg = distances[:, 1]
    tau = float(np.percentile(scores_bg, q_percent))
    return tau, scores_bg

def slide_decision(meta_count: int, total_tiles: int, ratio_thr: float, min_meta: int) -> str:
    ratio = (meta_count / max(total_tiles, 1))
    return "META" if (meta_count >= min_meta and ratio >= ratio_thr) else "NON_META"

# =========================
# ë©”ì¸
# =========================
def main():
    print("=== LNMP_KNN (Virchow2): META/NON-META ì¶”ë¡  (FAISS-KNN-Ï„, 5-NN ë§Œì¥ì¼ì¹˜, Single GPU) ===")

    # í…ŒìŠ¤íŠ¸ ìŠ¬ë¼ì´ë“œ ëª©ë¡
    test_ids = read_test_ids(TEST_IDS_TXT)
    print(f"- í…ŒìŠ¤íŠ¸ ìŠ¬ë¼ì´ë“œ ìˆ˜: {len(test_ids)}")

    # ë°°ê²½ ì„ë² ë”© ë¡œë“œ
    client = PersistentClient(path=str(DB_PATH))
    X_bg = build_bg_matrix_from_chroma(client, COLLECTION_NAME_BG, MAX_BG)
    print(f"- ë°°ê²½ ì„ë² ë”© ë¡œë“œ ì™„ë£Œ (shape={X_bg.shape})")

    # Ï„ ê³„ì‚°
    tau, bg_scores = calibrate_tau_with_bg_faiss_gpu(
        X_bg, k=1, q_percent=Q_PERCENT, batch_size=16, device=0
    )
    print(f"- tau (Q={Q_PERCENT}%): {tau:.6f}")

    # ì¶”ë¡ ìš© ì¸ë±ìŠ¤
    d = X_bg.shape[1]
    cpu_index = faiss.IndexFlatL2(d)
    res = faiss.StandardGpuResources()
    index = faiss.index_cpu_to_gpu(res, 0, cpu_index)
    index.add(X_bg.astype(np.float32))

    # ìŠ¬ë¼ì´ë“œë³„ ì¶”ë¡ 
    per_slide = []
    for sid in tqdm(test_ids, desc="Slides"):
        slide_dir = ROOT_DIR / sid / sid
        if not slide_dir.exists():
            alt_dir = ROOT_DIR / sid
            if alt_dir.exists():
                slide_dir = alt_dir

        tiles = list_tiles(slide_dir)
        if len(tiles) == 0:
            per_slide.append({"id": f"{sid}.svs", "metastasis": 0})
            continue

        # íƒ€ì¼ ë¡œë“œ
        imgs = []
        for tp in tiles:
            try:
                imgs.append(Image.open(tp).convert("RGB"))
            except:
                continue

        # GPU ì„ë² ë”©
        embs = embed_images(imgs, batch_size=256)

        # FAISS KNN ê²€ìƒ‰
        distances, _ = batched_search(index, embs, K_NEIGHBORS, batch_size=16)
        scores = distances[:, 1:K_NEIGHBORS+1]

        # âœ… 5ê°œ ëª¨ë‘ tauë³´ë‹¤ ì»¤ì•¼ META
        is_meta = np.all(scores > tau, axis=1)

        # ìŠ¬ë¼ì´ë“œ ì§‘ê³„
        meta_cnt = int(np.sum(is_meta))
        all_cnt = len(is_meta)
        slide_pred = slide_decision(meta_cnt, all_cnt, SLIDE_RATIO_THR, MIN_META_COUNT)

        per_slide.append({
            "id": f"{sid}.svs",
            "metastasis": 1 if slide_pred == "META" else 0
        })

        print(f"  - {sid}: tiles={all_cnt}, META={meta_cnt} "
              f"({(meta_cnt/all_cnt*100):.3f}%), -> {slide_pred}")

        # Overlay JPG ì €ì¥
        make_overlay_slide(
            slide_id=sid,
            tiles=tiles,
            is_meta=is_meta,
            tile_size=512,
            out_dir=BASE_ROOT_2 / "wsi_image_virchow2"
        )

    # ê²°ê³¼ JSON ì €ì¥
    out_json = BASE_ROOT_2 / f"lnmp_predictions_v0.3.0.json"
    with open(out_json, "w") as f:
        json.dump(per_slide, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {out_json}")


if __name__ == "__main__":
    main()

