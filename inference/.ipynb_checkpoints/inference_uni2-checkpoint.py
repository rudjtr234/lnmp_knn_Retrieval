#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, re, json
from pathlib import Path
from collections import defaultdict
from PIL import Image, ImageFile
import torch
import numpy as np
from chromadb import PersistentClient

import timm
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform
from timm.layers import SwiGLUPacked

ImageFile.LOAD_TRUNCATED_IMAGES = True

# =========================
# ì„¤ì •
# =========================
BASE_ROOT = Path("/home/mts/ssd_16tb/member/jks/lnmp_breast_data")
VERSION_DIR = BASE_ROOT / "V1.0.0"
ROOT_DIR = VERSION_DIR

TEST_IDS_TXT = BASE_ROOT / "test_ids.txt"

DB_PATH  = BASE_ROOT / "vectordb/lnmp_RAG_embedding_db_v0.1.0"
COLLECTION_NAME = "lnmp_tile_embeddings_UNI2"   # ì‹¤ì œ ì»¬ë ‰ì…˜ëª…ìœ¼ë¡œ í™•ì¸ ì™„ë£Œí–ˆìœ¼ë©´ ìœ ì§€

TOP_K = 3
VOTE_MODE = "weighted"       # "majority" | "weighted"
OUTPUT_PATH = Path("/home/mts/ssd_16tb/member/jks/lnmp_RAG/inference/result/predictions_v0.1.1.json")

USE_SOFTMAX = True
SOFTMAX_T   = 0.3
IMG_EXTS = (".jpg", ".jpeg", ".png")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
use_fp16 = (device.type == "cuda")

# =========================
# ëª¨ë¸ / ë³€í™˜
# =========================
timm_kwargs = {
    "img_size": 224, "patch_size": 14, "depth": 24, "num_heads": 24,
    "init_values": 1e-5, "embed_dim": 1536, "mlp_ratio": 2.66667*2,
    "num_classes": 0, "no_embed_class": True,
    "mlp_layer": SwiGLUPacked, "act_layer": torch.nn.SiLU,
    "reg_tokens": 8, "dynamic_img_size": True,
}
model = timm.create_model("hf-hub:MahmoodLab/UNI2-h", pretrained=True, **timm_kwargs).to(device)
model.eval()
data_cfg = resolve_data_config({}, model=model)
transform = create_transform(**data_cfg)

# =========================
# DB
# =========================
client = PersistentClient(path=str(DB_PATH))
collection = client.get_or_create_collection(name=COLLECTION_NAME)

# ì»¬ë ‰ì…˜ ë¹„ì–´ìˆìŒ ë°©ì§€ ì•ˆë‚´
try:
    _cnt = collection.count()
    if _cnt == 0:
        print(f"â— ê²½ê³ : ì»¬ë ‰ì…˜ '{COLLECTION_NAME}' ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì»¬ë ‰ì…˜ëª…ì„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
except Exception as e:
    print(f"â— ì»¬ë ‰ì…˜ ì¹´ìš´íŠ¸ ì‹¤íŒ¨: {e}")

# =========================
# ìœ í‹¸
# =========================
SLIDE_RE = re.compile(r"(BC_\d+_\d+)")
def l2_normalize(x: torch.Tensor, dim: int = -1, eps: float = 1e-12) -> torch.Tensor:
    return x / (x.norm(dim=dim, keepdim=True) + eps)

def softmax(x, T=1.0, eps=1e-12):
    x = np.array(x, dtype=np.float64) / max(T, eps)
    x = x - np.max(x)
    e = np.exp(x)
    return e / (np.sum(e) + eps)

def parse_test_list(path: Path):
    """
    test_ids.txt íŒŒì‹±:
      - ìŠ¬ë¼ì´ë“œ ID (BC_xx_xxxx) ë˜ëŠ” *.tiff â†’ slide ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
      - *.png ê²½ë¡œ/ì´ë¦„ â†’ í•´ë‹¹ ìŠ¬ë¼ì´ë“œì˜ tile whitelistì— ì¶”ê°€
    í•œ ì¤„ì— ì—¬ëŸ¬ IDê°€ ê³µë°±ìœ¼ë¡œ ë‚˜ì—´ë˜ì–´ ìˆì–´ë„ ëª¨ë‘ ì²˜ë¦¬.
    """
    slide_set = set()
    tile_whitelist = defaultdict(set)  # slide_id -> set(tile_basename_lower)
    if not path.exists():
        print(f"âš ï¸ test_ids.txtê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ìŠ¬ë¼ì´ë“œ ì‚¬ìš©: {path}")
        return slide_set, tile_whitelist, False

    with path.open("r", encoding="utf-8") as f:
        for raw in f:
            raw = raw.strip()
            if not raw or raw.startswith("#"):
                continue
            # ê³µë°± ë¶„ë¦¬ëœ í† í°ë“¤ì„ ëª¨ë‘ ì²˜ë¦¬
            for s in raw.split():
                sl = s.lower()
                if sl.endswith(".png"):
                    p = Path(s)
                    tile_name = p.name.lower()  # ëŒ€ì†Œë¬¸ì ë¬´ì‹œ
                    m = SLIDE_RE.search(s)
                    slide_id = m.group(1) if m else p.parent.name
                    slide_set.add(slide_id)
                    tile_whitelist[slide_id].add(tile_name)
                elif sl.endswith(".tiff") or sl.endswith(".svs"):
                    slide_id = Path(s).stem
                    slide_set.add(slide_id)
                else:
                    # ìŠ¬ë¼ì´ë“œ IDë¡œ ê°„ì£¼
                    slide_set.add(s)
    has_tile_filter = any(tile_whitelist.values())
    return slide_set, tile_whitelist, has_tile_filter

def resolve_search_dir(slide_root: Path) -> Path:
    """
    ìŠ¬ë¼ì´ë“œ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤ì œ íƒ€ì¼ì´ ìˆëŠ” ê²€ìƒ‰ ë£¨íŠ¸ ë°˜í™˜.
    /<sid>/<sid> êµ¬ì¡°ë©´ ì•ˆìª½ í´ë”ë¥¼, ì•„ë‹ˆë©´ í˜„ì¬ í´ë”ë¥¼ ë°˜í™˜.
    """
    nested = slide_root / slide_root.name
    return nested if nested.is_dir() else slide_root

# =========================
# ë©”ì¸
# =========================
def main():
    # test_ids ë¡œë“œ
    sel_slides, tile_filter, has_tile_filter = parse_test_list(TEST_IDS_TXT)
    # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ëŠ” ì†Œë¬¸ìë¡œ í†µì¼ë˜ì–´ ìˆìŒ(ìœ„ì—ì„œ lower ì ìš©)

    if sel_slides:
        print(f"ğŸ¯ ì„ íƒëœ ìŠ¬ë¼ì´ë“œ ìˆ˜: {len(sel_slides)} (tile í•„í„°: {has_tile_filter})")
    else:
        print("ğŸ¯ ì„ íƒ ìŠ¬ë¼ì´ë“œ ë¯¸ì§€ì • â†’ ì „ì²´ ì‚¬ìš©")

    # ì²˜ë¦¬ ëŒ€ìƒ ìŠ¬ë¼ì´ë“œ í´ë”(1-depthì—ì„œ ID ë§¤ì¹­)
    if sel_slides:
        targets = []
        missing = []
        for d in sorted([p for p in ROOT_DIR.iterdir() if p.is_dir()]):
            if d.name in sel_slides:
                targets.append(d)
        # ëˆ„ë½ í™•ì¸
        want = set(sel_slides)
        got = {d.name for d in targets}
        miss = sorted(list(want - got))
        if miss:
            print(f"â— test_idsì— ìˆìœ¼ë‚˜ 1-depthì— ì—†ëŠ” ìŠ¬ë¼ì´ë“œ(ìƒ˜í”Œ): {miss[:10]}")
        slide_dirs = targets
    else:
        slide_dirs = sorted([p for p in ROOT_DIR.iterdir() if p.is_dir()])

    results = []

    # ì»¬ë ‰ì…˜ í¬ê¸° í™•ì¸í•´ì„œ top_k ë³´ì •
    try:
        col_count = collection.count()
        effective_topk = max(1, min(TOP_K, col_count))
    except Exception:
        effective_topk = TOP_K

    for slide_dir in slide_dirs:
        slide_id = slide_dir.name

        # ğŸ” ì¤‘ì²© í´ë” ì§€ì› + ì¬ê·€ ìˆ˜ì§‘ + ëŒ€ì†Œë¬¸ì ë¬´ì‹œ
        search_dir = resolve_search_dir(slide_dir)
        tiles_all = [p for p in search_dir.rglob("*")
                     if p.is_file() and p.suffix.lower() in IMG_EXTS]

        if has_tile_filter and slide_id in tile_filter:
            want = tile_filter[slide_id]  # ì´ë¯¸ lower() set
            tile_paths = [p for p in tiles_all if p.name.lower() in want]
        else:
            tile_paths = tiles_all

        if not tile_paths:
            print(f"âš ï¸ íƒ€ì¼ ì—†ìŒ: slide={slide_id}  search_dir={search_dir}  ì˜ˆì‹œ={[p.name for p in tiles_all[:5]]}")
            continue

        vote_scores = {"metastasis": 0.0, "nonmetastasis": 0.0}
        total_votes = 0.0

        for path in tile_paths:
            try:
                with Image.open(path) as im:
                    img = im.convert("RGB")
                img_t = transform(img).unsqueeze(0).to(device)

                with torch.no_grad():
                    if use_fp16:
                        with torch.cuda.amp.autocast(dtype=torch.float16):
                            feats = model(img_t)          # (1, 1536)
                    else:
                        feats = model(img_t)

                feats = l2_normalize(feats, dim=-1)
                embedding = feats.squeeze(0).detach().cpu().tolist()

                q = collection.query(
                    query_embeddings=[embedding],
                    n_results=effective_topk,
                    include=["metadatas", "distances"]
                )
                if not q.get("metadatas") or not q["metadatas"][0]:
                    continue

                metas = q["metadatas"][0]
                dists = q.get("distances", [[]])[0]
                sims  = [1.0 - float(d) for d in dists]

                if VOTE_MODE == "majority":
                    weights = [1.0] * len(metas)
                elif VOTE_MODE == "weighted":
                    if USE_SOFTMAX:
                        weights = softmax(sims, T=SOFTMAX_T)
                    else:
                        s = np.clip(np.asarray(sims, dtype=np.float64), 0.0, None)
                        weights = s / (s.sum() if s.sum() > 0 else 1.0)
                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” vote_mode: {VOTE_MODE}")

                for m, w in zip(metas, weights):
                    lbl = m.get("label")
                    if lbl in vote_scores:
                        vote_scores[lbl] += float(w)
                    total_votes += float(w)

            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {path} â†’ {e}")

        pred = max(vote_scores.items(), key=lambda x: x[1])[0]
        print(f"\nâœ… {slide_id} | pred={pred}, scores={vote_scores}, mode={VOTE_MODE}, top_k={effective_topk}, tiles={len(tile_paths)}")
        print(f"ğŸ§® total weighted votes: {total_votes:.4f}")
        results.append({"id": f"{slide_id}.tiff", "prediction": pred})

    # ì €ì¥
    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    with OUTPUT_PATH.open("w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ“ ê²°ê³¼ ì €ì¥: {OUTPUT_PATH}  (n={len(results)})")

if __name__ == "__main__":
    main()
